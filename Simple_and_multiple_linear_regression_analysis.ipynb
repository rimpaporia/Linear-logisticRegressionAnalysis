{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Model:\n",
    "The Simple Linear Regression model can be represented using the below equation:\n",
    "\n",
    "y= a0+a1x+ ε \n",
    "Where,\n",
    "\n",
    "a0= It is the intercept of the Regression line (can be obtained putting x=0)\n",
    "a1= It is the slope of the regression line, which tells whether the line is increasing or decreasing.\n",
    "ε = The error term. (For a good model it will be negligible)\n",
    "\n",
    "Implementation of Simple Linear Regression Algorithm using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement example for Simple Linear Regression:\n",
    "\n",
    "Here we are taking a dataset that has two variables: salary (dependent variable) and experience (Independent variable). The goals of this problem is:\n",
    "\n",
    "We want to find out if there is any correlation between these two variables\n",
    "We will find the best fit line for the dataset.\n",
    "How the dependent variable is changing by changing the dependent variable.\n",
    "In this section, we will create a Simple Linear Regression model to find out the best fitting line for representing the relationship between these two variables.\n",
    "\n",
    "To implement the Simple Linear regression model in machine learning using Python, we need to follow the below steps:\n",
    "\n",
    "# Step-1: Data Pre-processing\n",
    "\n",
    "The first step for creating the Simple Linear Regression model is data pre-processing. We have already done it earlier in this tutorial. But there will be some changes, which are given in the below steps:\n",
    "\n",
    "First, we will import the three important libraries, which will help us for loading the dataset, plotting the graphs, and creating the Simple Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nm  \n",
    "import matplotlib.pyplot as mtp  \n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load the dataset into our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set= pd.read_csv('Salary_Data.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>39343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>46205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>37731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>39891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>56642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>54445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>64445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>57189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.9</td>\n",
       "      <td>63218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.1</td>\n",
       "      <td>57081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4.5</td>\n",
       "      <td>61111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.9</td>\n",
       "      <td>67938.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>5.1</td>\n",
       "      <td>66029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.3</td>\n",
       "      <td>83088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.9</td>\n",
       "      <td>81363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>91738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>7.1</td>\n",
       "      <td>98273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>7.9</td>\n",
       "      <td>101302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>8.2</td>\n",
       "      <td>113812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>8.7</td>\n",
       "      <td>109431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>9.0</td>\n",
       "      <td>105582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>9.5</td>\n",
       "      <td>116969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>9.6</td>\n",
       "      <td>112635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>10.3</td>\n",
       "      <td>122391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>10.5</td>\n",
       "      <td>121872.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YearsExperience    Salary\n",
       "0               1.1   39343.0\n",
       "1               1.3   46205.0\n",
       "2               1.5   37731.0\n",
       "3               2.0   43525.0\n",
       "4               2.2   39891.0\n",
       "5               2.9   56642.0\n",
       "6               3.0   60150.0\n",
       "7               3.2   54445.0\n",
       "8               3.2   64445.0\n",
       "9               3.7   57189.0\n",
       "10              3.9   63218.0\n",
       "11              4.0   55794.0\n",
       "12              4.0   56957.0\n",
       "13              4.1   57081.0\n",
       "14              4.5   61111.0\n",
       "15              4.9   67938.0\n",
       "16              5.1   66029.0\n",
       "17              5.3   83088.0\n",
       "18              5.9   81363.0\n",
       "19              6.0   93940.0\n",
       "20              6.8   91738.0\n",
       "21              7.1   98273.0\n",
       "22              7.9  101302.0\n",
       "23              8.2  113812.0\n",
       "24              8.7  109431.0\n",
       "25              9.0  105582.0\n",
       "26              9.5  116969.0\n",
       "27              9.6  112635.0\n",
       "28             10.3  122391.0\n",
       "29             10.5  121872.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows the dataset, which has two variables: Salary and YearsExperience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we need to extract the dependent and independent variables from the given dataset. The independent variable is years of experience, and the dependent variable is salary. Below is code for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= data_set.iloc[:, :-1].values  \n",
    "y= data_set.iloc[:, 1].values   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above lines of code, for x variable, we have taken -1 value since we want to remove the last column from the dataset. For y variable, we have taken 1 value as a parameter, since we want to extract the second column and indexing starts from the zero.\n",
    "\n",
    "By executing the above line of code, we will get the output for X and Y variable as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1],\n",
       "       [ 1.3],\n",
       "       [ 1.5],\n",
       "       [ 2. ],\n",
       "       [ 2.2],\n",
       "       [ 2.9],\n",
       "       [ 3. ],\n",
       "       [ 3.2],\n",
       "       [ 3.2],\n",
       "       [ 3.7],\n",
       "       [ 3.9],\n",
       "       [ 4. ],\n",
       "       [ 4. ],\n",
       "       [ 4.1],\n",
       "       [ 4.5],\n",
       "       [ 4.9],\n",
       "       [ 5.1],\n",
       "       [ 5.3],\n",
       "       [ 5.9],\n",
       "       [ 6. ],\n",
       "       [ 6.8],\n",
       "       [ 7.1],\n",
       "       [ 7.9],\n",
       "       [ 8.2],\n",
       "       [ 8.7],\n",
       "       [ 9. ],\n",
       "       [ 9.5],\n",
       "       [ 9.6],\n",
       "       [10.3],\n",
       "       [10.5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39343.,  46205.,  37731.,  43525.,  39891.,  56642.,  60150.,\n",
       "        54445.,  64445.,  57189.,  63218.,  55794.,  56957.,  57081.,\n",
       "        61111.,  67938.,  66029.,  83088.,  81363.,  93940.,  91738.,\n",
       "        98273., 101302., 113812., 109431., 105582., 116969., 112635.,\n",
       "       122391., 121872.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above output image, we can see the X (independent) variable and Y (dependent) variable has been extracted from the given dataset.\n",
    "\n",
    "Next, we will split both variables into the test set and training set. We have 30 observations, so we will take 20 observations for the training set and 10 observations for the test set. We are splitting our dataset so that we can train our model using a training dataset and then test the model using a test dataset. The code for this is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 1/3, random_state=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By executing the above code, we will get x-test, x-train and y-test, y-train dataset. Consider the below images:\n",
    "\n",
    "Test-dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.5],\n",
       "        [10.3],\n",
       "        [ 4.1],\n",
       "        [ 3.9],\n",
       "        [ 9.5],\n",
       "        [ 8.7],\n",
       "        [ 9.6],\n",
       "        [ 4. ],\n",
       "        [ 5.3],\n",
       "        [ 7.9]]),\n",
       " array([ 37731., 122391.,  57081.,  63218., 116969., 109431., 112635.,\n",
       "         55794.,  83088., 101302.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.9],\n",
       "        [ 5.1],\n",
       "        [ 3.2],\n",
       "        [ 4.5],\n",
       "        [ 8.2],\n",
       "        [ 6.8],\n",
       "        [ 1.3],\n",
       "        [10.5],\n",
       "        [ 3. ],\n",
       "        [ 2.2],\n",
       "        [ 5.9],\n",
       "        [ 6. ],\n",
       "        [ 3.7],\n",
       "        [ 3.2],\n",
       "        [ 9. ],\n",
       "        [ 2. ],\n",
       "        [ 1.1],\n",
       "        [ 7.1],\n",
       "        [ 4.9],\n",
       "        [ 4. ]]),\n",
       " array([ 56642.,  66029.,  64445.,  61111., 113812.,  91738.,  46205.,\n",
       "        121872.,  60150.,  39891.,  81363.,  93940.,  57189.,  54445.,\n",
       "        105582.,  43525.,  39343.,  98273.,  67938.,  56957.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple linear Regression, we will not use Feature Scaling. Because Python libraries take care of it for some cases, so we don't need to perform it here. Now, our dataset is well prepared to work on it and we are going to start building a Simple Linear Regression model for the given problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-2: Fitting the Simple Linear Regression to the Training Set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the second step is to fit our model to the training dataset. To do so, we will import the LinearRegression class of the linear_model library from the scikit learn. After importing the class, we are going to create an object of the class named as a regressor. The code for this is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the Simple Linear Regression model to the training dataset  \n",
    "from sklearn.linear_model import LinearRegression  \n",
    "regressor= LinearRegression()  \n",
    "regressor.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we have used a fit() method to fit our Simple Linear Regression object to the training set. In the fit() function, we have passed the x_train and y_train, which is our training dataset for the dependent and an independent variable. We have fitted our regressor object to the training set so that the model can easily learn the correlations between the predictor and target variables. After executing the above lines of code, we will get the below output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step: 3. Prediction of test set result:\n",
    "\n",
    "dependent (salary) and an independent variable (Experience). So, now, our model is ready to predict the output for the new observations. In this step, we will provide the test dataset (new observations) to the model to check whether it can predict the correct output or not.\n",
    "\n",
    "We will create a prediction vector y_pred, and x_pred, which will contain predictions of test dataset, and prediction of training set respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of Test and Training set result  \n",
    "y_pred= regressor.predict(x_test)  \n",
    "x_pred= regressor.predict(x_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On executing the above lines of code, two variables named y_pred and x_pred will generate in the variable explorer options that contain salary predictions for the training set and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "You can check the variable by clicking on the variable explorer option in the IDE, and also compare the result by comparing values from y_pred and y_test. By comparing these values, we can check how good our model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 40835.10590871, 123079.39940819,  65134.55626083,  63265.36777221,\n",
       "        115602.64545369, 108125.8914992 , 116537.23969801,  64199.96201652,\n",
       "         76349.68719258, 100649.1375447 ]),\n",
       " array([ 53919.42532909,  74480.49870396,  56723.20806202,  68872.93323808,\n",
       "        103452.92027763,  90368.60085726,  38965.91742009, 124948.58789682,\n",
       "         54854.0195734 ,  47377.2656189 ,  81957.25265845,  82891.84690277,\n",
       "         61396.17928358,  56723.20806202, 110929.67423213,  45508.07713028,\n",
       "         37096.72893147,  93172.3835902 ,  72611.31021533,  64199.96201652]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred,x_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step: 4. visualizing the Training set results:\n",
    "\n",
    "Now in this step, we will visualize the training set result. To do so, we will use the scatter() function of the pyplot library, which we have already imported in the pre-processing step. The scatter () function will create a scatter plot of observations.\n",
    "\n",
    "In the x-axis, we will plot the Years of Experience of employees and on the y-axis, salary of employees. In the function, we will pass the real values of training set, which means a year of experience x_train, training set of Salaries y_train, and color of the observations. Here we are taking a green color for the observation, but it can be any color as per the choice.\n",
    "\n",
    "Now, we need to plot the regression line, so for this, we will use the plot() function of the pyplot library. In this function, we will pass the years of experience for training set, predicted salary for training set x_pred, and color of the line.\n",
    "\n",
    "Next, we will give the title for the plot. So here, we will use the title() function of the pyplot library and pass the name (\"Salary vs Experience (Training Dataset)\".\n",
    "\n",
    "After that, we will assign labels for x-axis and y-axis using xlabel() and ylabel() function.\n",
    "\n",
    "Finally, we will represent all above things in a graph using show(). The code is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mtp.scatter(x_train, y_train, color=\"green\")   \n",
    "mtp.plot(x_train, x_pred, color=\"red\")    \n",
    "mtp.title(\"Salary vs Experience (Training Dataset)\")  \n",
    "mtp.xlabel(\"Years of Experience\")  \n",
    "mtp.ylabel(\"Salary(In Rupees)\")  \n",
    "mtp.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot, we can see the real values observations in green dots and predicted values are covered by the red regression line. The regression line shows a correlation between the dependent and independent variable.\n",
    "\n",
    "The good fit of the line can be observed by calculating the difference between actual values and predicted values. But as we can see in the above plot, most of the observations are close to the regression line, hence our model is good for the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step: 5. visualizing the Test set results:\n",
    "\n",
    "In the previous step, we have visualized the performance of our model on the training set. Now, we will do the same for the Test set. The complete code will remain the same as the above code, except in this, we will use x_test, and y_test instead of x_train and y_train.\n",
    "\n",
    "Here we are also changing the color of observations and regression line to differentiate between the two plots, but it is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxcVZn/8c83C0sg7AFDtkaDIKCM0LIoIgPIoiLoyIATJSr+MqOiorigqAwIbggoikAEhqCRyICaiKyi44KyJIAsBkiQbKxhCRCCkOX5/XFOk1vV1UuSqrpd3d/361Wvvvfc7anb3fXUOffccxURmJmZ1dOgsgMwM7P+x8nFzMzqzsnFzMzqzsnFzMzqzsnFzMzqzsnFzMzqzsnF1pikeZIOLDuOViRpqaRXlx1HkaRvSjq+7DhalaRhku6XtHnZsfQlTi4DlKR9JP1F0rOSnpZ0k6Q3lR1XI0i6RNLL+YO94/W3MmKJiI0j4h9lHLsWSSOAY4ALJE0onJ8XJa0qnrN1OMaOklb0sM63JC2X9Hx+3Sfp+5K2XoPj3CzpA2sb59oeJyKWAVOBzzX62K3EyWUAkrQJcBXwA2ALYBRwCvBSg487pJH778F38gd7x2vXZh685PfenQ8BV0fEixExteP8AIcCjxTPWRNimRIRw4EtgSOBNmBmToB93VTg2D78e246J5eB6bUAEXFZRKzMHyzXR8RdAJJeI+l3kp6S9KSkqZI2q7UjSXtI+qukJZIelfRDSesVloekT0iaA8yRdK6kM6v28etazTKSzpf03aqy6ZI+m6e/KOnh/E33fkkHrOmJkHSUpH/khIukQyU91vGBluP/VF7nSUlnSBpU2P4jkmZLekbSdZLGdfXeC2Xj8/T6kr4raYGkx/P73TAv20/SIkknSHoin9sPF/a9oaQzJc3Ptc8/F7bdK9dKl0j6m6T9ujkFhwJ/WIPzNSb/Dp7M5+S/CsveIukOSc/lc/jNvOiPwOBCLeiN3R0jIl6OiLuB9wEvAJ/O+x8h6RpJi3Nte7qkkXnZmcCbgAvzMc7M5efl8/icpFsl7dWLeJH0Vkm35HN4u6S3dHeciHgQWA7s3ttz2e9FhF8D7AVsAjwFTCF9uGxetXw88HZgfWAE6cPhe4Xl84AD8/TuwF7AENI3zdnA8YV1A7iBVEPaENgDeAQYlJdvBSwDtqkR577AQkB5fnPgRWBbYIe8bNu8rA14TRfv9xLgtG7Ox9S8zpY5tndVxf/7HP9Y4AHgo3nZEcBc4HX5/X8F+EtX771QNj5Pfw+YkZcPB34NfDMv2w9YAZwKDAXekc/T5nn5ucD/kWqdg4E359/XqPy7fQfpy+Pb8/yILt77YuBNNcr3AxZVlQ0G7ga+CKxH+pKyAHhbXn4HcGSeHg7smad3BFb08Df5LeDCGuXfAf6Qp7cBDs9/R5sC04FphXVvBj5Qtf0x+e9mKHBS/psZ2kO8bfmcHZjP4Tvyedq8q+Pk8uuBSWX/f/eVV+kB+FXSLz59IF4CLMofYjOo8QGf1z0CuKMwP4+cXGqsezzwy8J8APtXrTMbeHuePo7ULFNrX8ofXvvm+f8H/C5PjweeyB8AQ3t4r5cA/wSWFF5TCss3y8e5G7igatsADinMfxy4MU9fAxxbWDaIlADGdfPeI8cu0rfy1xSW7Q08lKf3IyXSIYXlT5AS+aC8bNca7/WLwE+qyq4DJnZxbpYDO9Yo34/OyeVtwJyqslOA8/L0raQP8C2r1lmX5HI8cHcX2+wFPFqYr/mhX/X3tAzYoYd4TwZ+XFX2B+Co7o4DXAl8YU3/F/vry81iA1REzI6ID0XEaGAXUm3gewCStpY0LTc5PQf8lFTD6ETSayVdlZsVngO+UWPdhVXzU4COC6IfAH7SRYwBTAPen4v+g1TLICLmkj54/ht4Ise7bTdv+bsRsVnhNbFwnCXA/+bzcGaNbYvxzyedK4BxwPdz08kS4GnSB9ioLrYtGgEMA2YVtr82l3d4KiKKF8KXARuTzu8GwIM19jsOOLJjn3m/+wAju4jjGdK39t4YB7RV7fuzwKvy8onAG4AHcpPSwb3cb3dGkc4rkoZLujg3Iz5HqinU/LvsIOlLucn0WdJ73aCwTVfxjgM+UPU+21n9e+/KcNIXF8PXXAyIiPtI3+53yUXfJH3DfkNEbEJKAOpi8/OA+4Dt87pfrrFu9dDbPwUOl7QrqQb1q27Cuwx4X76WsSfp22FH3D+LiH1IHwYBfLub/XRJ0r8AH8nHOqfGKmMK02NJTWeQEsd/ViWtDSPiL4X1uxp2/ElS7WPnwrabRu8unD9Jqom9psayhaSaSzGmjSLiW13s6y7yNbheWAjcV7Xv4RHxHnjlC8tRwNak8/gLpetvazX0utLF8XcBf8pFJwKjSc14mwAHUfm3FlXbvx34JPAeUu10C9I5Vw/xLiTVoqrP4dm1jlPwOqCUXoh9kZPLAKTUNfQESaPz/BhS7eDmvMpwYCmwRNIo4PPd7G448BywVNKOwMd6On5ELAJuI9VYroyIF7tZ9w5Se/eFwHW5loGkHSTtL2l90gfti8DKno5dTdIGpGT3ZeDDwChJH69a7fOSNs/n6dPAz3P5+cCXJO2c97WppCN7c9yIWAX8GDhbubutpFG9+baft70YOEvStpIGS9o7n4ufAodJOjiXb5A7B4zuYndXk5q7euPPOc7j836HSHqDpN1y+TGStoyIlcCzpA/hVaTmvMGSxvbmIJKG5nN6OenvqyPhDyfV3pZI2op0javocaB4D9FwUrPfYtI1olNJNZeO43QV7xRS7e+AfA43zNOv6uI4KN27tB4wqzfvcUAou13Or+a/SE0NlwMPk9r9HwYuADbJy3cm/ZMsBe4ETqDQ/k7lBf19STWXpaRvmKcCfy6s+8oF7KoYPpCX/Wsv4v1qXvfIQtkbSG3mz5OaTa4iX9yvsf0lwMs5xo7Xk3nZ2cC1hXV3zfvbvhD/p4B/kC7yngkMLqz/QdK1mudI33gv7u69F8tIH3TfyPt+jnQt6lN52X50vuZRPO8bkpoxHyZ9MP6R1Z0G9iRdI3ia9MH6G2BsF+dmK9J1tw2ryjsdP5ePyX87j5OamW5i9TWxy0m1qufzOXlHYbtv51iWAP9SY7/fIiWC50l/kw+QusqPLKwzlpTglua/uY9TuJZDSpJzc1zfIV3E/0k+tw+TmlEfA/bpRbxvycd6hpQcZ7C680jFcQp/o98o+3+7L706euGYNZWkfUnfstsifRPvkyQFKdHMLTuWRpH0DeCJiPhe2bG0IknDSD3P9o6Ip8uOp69wcrGmkzSUdKH+bxFxatnxdGcgJBezRvA1F2sqSa8jNY2MJPdOM7P+xzUXMzOrO9dczMys7jzIWrbVVltFW1tb2WGYmbWUWbNmPRkRnQYXdXLJ2tramDlzZtlhmJm1FEnza5W7WczMzOrOycXMzOrOycXMzOrOycXMzOrOycXMzOrOycXMzOrOycXMzOrOycXMbKB64AE47TRYvrzuu3ZyMTMbaCLgyCNhhx3gq1+FRx7peZs15Dv0zcwGklmzoL199fxPfgLjxtX9ME4uZmYDwapV8Na3wl/+kua32Qbmz4f112/I4dwsZmbWj02dCv+xzY0wePDqxHLNNfDYYw1LLODkYmbWb/1synL2+WAbP3viQABu540M33AFU586pOHHdnIxM+uP/vd/+Y8Prce4SIMW78Vf2Z3bWfriYE46qfGH9zUXM7P+5IUXYPPNX+lefBXv5DB+DeiVVRYsaHwYrrmYmfUX550HG2/8SmI5cOS9HMZVFBMLwNixjQ+lYclF0sWSnpB0T6HsDEn3SbpL0i8lbVZY9iVJcyXdL+ngQvkhuWyupBML5dtJukXSHEk/l7ReLl8/z8/Ny9sa9R7NzPqEp54CCT7+8TQ/aRJE8OEzdmLYsMpVhw2D009vfEiNrLlcAlRfNboB2CUi3gA8AHwJQNJOwNHAznmbH0kaLGkwcC5wKLAT8P68LsC3gbMjYnvgGeDYXH4s8ExEjAfOzuuZmfVPp5wCW221en7+fLjgAgAmTIDJk9NtLFL6OXlyKm+0hiWXiPgj8HRV2fURsSLP3gyMztOHA9Mi4qWIeAiYC+yRX3Mj4h8R8TIwDThckoD9gSvy9lOAIwr7mpKnrwAOyOubmfUfCxemjPHf/53mv/a1dOd9VZvXhAkwb166zWXevOYkFij3mstHgGvy9ChgYWHZolzWVfmWwJJCouoor9hXXv5sXr8TSZMkzZQ0c/Hixev8hszMmuLjH69MIosXpxpMH1JKcpF0ErACmNpRVGO1WIvy7vbVuTBickS0R0T7iBEjug/azKxss2en2sp556X5H/wg1VaKzWJ9RNO7IkuaCLwLOCAiOj70FwFjCquNBjpGUqtV/iSwmaQhuXZSXL9jX4skDQE2pap5zsyspUTAe94D06en+UGD4NlnU8+wPqqpNRdJhwBfBN4dEcsKi2YAR+eeXtsB2wO3ArcB2+eeYeuRLvrPyEnp98D78vYTgemFfU3M0+8DfldIYmZmreXWW1My6Ugs06bBypV9OrFAY7siXwb8FdhB0iJJxwI/BIYDN0i6U9L5ABFxL3A58HfgWuATEbEy10qOA64DZgOX53UhJanPSppLuqZyUS6/CNgyl38WeKX7splZXzF1KrS1pbzR1pbmK6xcmUYv3nPPND9mDLz0Ehx1VJMjXTvyl/qkvb09Zs6cWXYYZjYATJ2abkVZVmi/GTas0E34uuvgkMKdHNdfD29/e9Pj7A1JsyKivVO5k0vi5GJmzdLWlm5HqTZ+7MvMWd4Gjz6aCvbcM41kPKjvDqbSVXLpuxGbmfVTtcb2OoppzFmw/urEcsstcPPNfTqxdMcDV5qZNdnYsatrLhuxlKUMX73wPe+BK69MXY5bWGumRDOzFnb66ekayyc5pyKxzPjOffCLX7R8YgHXXMzMmm7CQYuZsGzrV+Yv3fjjDD7/3KYNzdIMTi5mZs30la9UDku8cCHHjB7d9fotys1iZmbNMH9+au7qSCynnpruvO+HiQVcczEza7yPfhQuumj1/FNPwRZblBdPE7jmYmbWKPfem2orHYnl/PNTbaUqsfR4t34Lcs3FzKzeIuCd74Rr8lNFNtgg1VaqHwtJ57v1589P89C8Z680gmsuZmb11HFHfUdiueIKePHFmokF4KSTKoeBgTR/0kkNjrPBXHMxM6uHlStht93grrvS/KtfDffdB0OHdrtZrbv1uytvFa65mJmtq6uvhiFDVieWG2+EBx/sMbFAp6cS91jeKpxczMzW1ksvwYgR6foKwD77pBrM/vv3ehcdd+sXDRtWeStMK3JyMTNbGwcfnC7UP/lkmp85E/70pzUeaHLChDTU/rhxqWPZuHGFofdbmJOLmVlBj92CFy1KWeD661eXrVoFu+++1secMAHmzUu7mTev9RMLOLmYmb2io1vw/PmpN3FHt+BXEszo0emJkB2uvjqt2A8Gmqw3Jxczs6yrbsGXfv7ulEAefnj1ggg49NDmBthC3BXZzCyr1f03EDxaKJg5c52awAYK11zMzLJi99/9uTEllg6bbJJqK04sveLkYmaWdXQLDsSNHPhK+a/OfgiefbbEyFqPk4uZWTYhfsoLy1bXVmatvzdTfxoccXxbeUG1KF9zMTNbtQoGD64se+opdt9iC9wItnZcczGzge0b36hMLBMn1hwW39aMay5mNjC99FK6w77oxRc7l9lacc3FzAaej360MomcckqqrTix1I1rLmY2cDzzTOfmrpUr13g8MOuZz6iZDQz77luZWC65JNVWnFgawjUXM+vf5s9PI1AWRZQSykDilG1m/deWW1Ymluuvd2JpEtdczKz/mTkT3vSmyjInlaZycjGz/qV6+Ps774Rddy0nlgHMzWJm1j+ce27nxBLhxFISJxczawndPiFSguOOWz1/zz1uBiuZk4uZ9XldPSHyvoM/Vbu2svPO5QRqr/A1FzPr86qfEDmYFbywbCgUHmPPY4/BNts0PTarrWE1F0kXS3pC0j2Fsi0k3SBpTv65eS6XpHMkzZV0l6TdCttMzOvPkTSxUL67pLvzNudI6etLV8cws9ZVfELk79mPFQxdXTBqVKqtOLH0KY1sFrsEOKSq7ETgxojYHrgxzwMcCmyfX5OA8yAlCuBkYE9gD+DkQrI4L6/bsd0hPRzDzFrU2LGwMc8TiP34wyvlO455ARYtKjEy60rDkktE/BF4uqr4cGBKnp4CHFEovzSSm4HNJI0EDgZuiIinI+IZ4AbgkLxsk4j4a0QEcGnVvmodw8xa1NzHNuJ5NnllfjrvZqNhwVe/OazEqKw7zb7msk1EPAoQEY9K2jqXjwIWFtZblMu6K19Uo7y7Y3QiaRKp9sPY4sOzzaxvWLgQxo6t+KAazErGjBvE5NNhwoTSIrMedJtcJG0AvAt4K7At8CJwD/CbiLi3jnGoRlmsRfkaiYjJwGSA9vZ291s060uqe4F9+ctw+umsLCcaW0NdJhdJ/w0cBvwfcAvwBLAB8FrgWznxnBARd63B8R6XNDLXKEbmfUKqeYwprDcaeCSX71dV/n+5fHSN9bs7hpm1glmzoL29ssz3rLSc7q653BYRu0fECRHxs4j4bURcFRFnRcRhwARgvTU83gygo8fXRGB6ofyY3GtsL+DZ3LR1HXCQpM3zhfyDgOvysucl7ZV7iR1Tta9axzCzvk6qTCwdw+Jby+my5hIRv6kukzQI2DginouIJ+imViDpMlKtYytJi0i9vr4FXC7pWGABcGRe/WrgHcBcYBnw4RzD05K+DtyW1zs1Ijo6CXyM1CNtQ+Ca/KKbY5hZXzV9OhxR1ffGSaWlKXr4BUr6GfBfwEpgFrApcFZEnNH48Jqnvb09Zs6cWXYYZgNP9bWV3/8e9tuvlFBszUmaFRHt1eW96Yq8U0Q8R+rSezUwFvhgneMzs4HmzDNrD93ixNIv9KYr8lBJQ0nJ5YcRsVyS66tmtnZqPVr4vvtghx3Kiccaojc1lwuAecBGwB8ljQOea2RQZtZPffSjnRNLhBNLP9RjzSUizgHOKRTNl/SvjQvJzPqd5cthvarOpYsXw1ZblROPNVyPNRdJ20i6SNI1eX4nVnf1NTPr3h57VCaWHXZItRUnln6tN81il5DuN9k2zz8AHN+ogMysn1iyJF2wv+221WX//Ge6vmL9Xm+Sy1YRcTmwCiAiVoBHYDCzbkiweeFpF0cfnWor669fXkzWVL3pLfaCpC3JY3d13EHf0KjMrDU99BC8+tWVZatWde5ybP1eb2ounyUNqfIaSTeRhrf/ZEOjMrPWI1UmllNPTbUVJ5YBqTe9xW6X9DZgB9JoxPdHxPKGR2ZmreE3v4F3vauyzEO3DHi96S02jPQ0x+Mj4h6gTdK7etjMzAYCqTKxXHaZE4sBvWsW+x/gZWDvPL8IOK1hEZlZ39fV0C1HH11OPNbn9OaC/msi4ihJ7weIiBfzMPdmNhBV//vPmAGHHVZOLNZn9abm8rKkDVndW+w1wEsNjcrM+p4PfrB2bcWJxWroTc3lZOBaYIykqcBbgA81Migz60NqDTT5t7/BG95QTjzWEnrTW+wGSbcDe5F6i306Ip5seGRmVr7XvhbmzKks8wV764Xe1FwA3gbsQ2oaGwr8smERmVn5XnwRhg2rLHv8cdh663LisZbTY3KR9CNgPHBZLvpPSQdGxCcaGpmZlaNWfx3XVmwN9abm8jZgl8jPQ5Y0Bbi7oVGZWfM9+ihsu21l2T//6fHAbK30prfY/aRHG3cYA9zVmHDMrBRSZWJ5/es90KStk97UXLYEZku6Nc+/CfirpBkAEfHuRgVnZg12xx2w226VZR5o0uqgN8nlaw2PwsyarzqBHHssXHhhObFYv9Obrsh/aEYgZtYkV14J73tfZZkv2Fud9WbgyuclPZdf/5S0UtJzzQjOzOpMqkwsP/iBE4s1RG9qLsOL85KOAPZoWERmVn+nnQZf/WplmZOKNVBvb6J8RUT8StKJjQjGzBqg+trKddfBQQeVE4sNGL25ifK9hdlBQDt5EEsz68Pe+174ZdVgGq6tWJP0puZSHPJ0BTAPOLwh0ZjZulu1CgYPriybPRt23LGceGxA6s01lw9Xl0naqDHhmNk6edWr0hhgRa6tWAm67S0maZSkdknr5fmtJX0DmNPddmYGU6dCW1sarb6tLc03zNKl6dpKMbE89ZQTi5Wmy+Qi6XjgTuAHwM2SJgKzgQ2B3ZsTnllrmjoVJk2C+fPT5/v8+Wm+IQlGguHDK8siYIstGnAws95RdPHNRtLfgX0i4mlJY4G5wL4RcXMzA2yW9vb2mDlzZtlhWD/R1pYSSrVx42DevDodZMGCtMOil1+GoUPrdACznkmaFRHt1eXdNYv9MyKeBoiIBcAD/TWxmNXbggVrVr7GpMrEsvfeqbbixGJ9RHcX9EdLOqcwv3VxPiI+1biwzFrb2LG1ay5jx3YuWyM33ND5HhUPNGl9UHfJ5fNV87MaGYhZf3L66ekay7Jlq8uGDUvla606gbzjHfCb36zDDs0ap8vkEhFTmhmIWX8yYUL6edJJqSls7NiUWDrK18jZZ8NnP1tZ5l5g1sf15mFhdSfpM5LulXSPpMskbSBpO0m3SJoj6eeF7s/r5/m5eXlbYT9fyuX3Szq4UH5ILpvroWqsLBMmpIv3q1aln2uVWKTKxPL1rzuxWEtoenKRNAr4FNAeEbsAg4GjgW8DZ0fE9sAzwLF5k2OBZyJiPHB2Xg9JO+XtdgYOAX4kabCkwcC5wKHATsD787pmreP97+/cDBYBX/lKOfGYraFSai6k5rgNJQ0BhgGPAvsDV+TlU4Aj8vTheZ68/ABJyuXTIuKliHiI1FV6j/yaGxH/iIiXgWl4uBprJRJMm7Z6/le/cm3FWk5vBq4cAfw/oK24fkR8ZG0OGBEPS/ousAB4Ebie1FlgSUSsyKstAkbl6VHAwrztCknPkh69PAoodo0ubrOwqnzPLt7bJGASwNh17sZjto5GjoTHHqssc1KxFtWbmst0YFPgt8BvCq+1ImlzUk1iO2BbYCNSE1a1jv+qWn0sYy3KOxdGTI6I9ohoHzFiRE+hmzXGihWptlJMLPfc48RiLa03oyIPi4gv1vGYBwIPRcRiAEm/AN4MbCZpSK69jAYeyesvAsYAi3Iz2qbA04XyDsVtuio361tq3Z/ipGL9QG9qLldJekcdj7kA2EvSsHzt5ADg78DvgY7nr04k1ZgAZuR58vLfRRqzZgZwdO5Nth2wPXArcBuwfe59th7pov+MOsZvtu6efrpzYnnySScW6zd6U3P5NPBlSS8By0nNThERm6zNASPiFklXALeTng9zBzCZ1NQ2TdJpueyivMlFwE8kzSXVWI7O+7lX0uWkxLQC+ERErASQdBxwHakn2sURce/axGrWEK6t2ADQ5cCVA40HrrSGu/de2GWXyrLly2HIGj9t3KzP6Grgyi7/qiXt1t0OI+L2egRmNiBU11a23rrzQ73M+pHuvjKd2c2yIN2XYmbdmTEDDq+6zcqtBTYAdDe22L82MxCzfqe6tnLUUZU3R5r1Y909iXKf7jaUtImkXbpbx2xAOv302kO3OLHYANJds9i/SfoOcC3pDvrFwAbAeOBfgXHACQ2P0KyVVCeVM8/sPKKx2QDQXbPYZ/Ld9O8DjgRGkoZrmQ1cEBF/bk6IZi3gsMPgqqsqy3xtxQawbvtARsQzki6OiB83KyCzlhIBg6pal6+9Fg4+uPb6ZgNEbzrYz803PV4cEbMbHZBZy/DNkGZd6s3wL28AHgAuknSzpEmS1urufLN+4aWXOieWu+5yYjEr6DG5RMTzEfHjiHgz8AXgZOBRSVMkjW94hGZ9iQQbbFBZFgGvf3058Zj1UT0ml/x0x3dL+iXwfdLNla8Gfg1c3eD4zPqGhx/uXFt56inXVsy60JtrLnNIIxafERF/KZRfIWnfxoRl1of42orZGuu25pKfR39JRBxblVgAiIhPNSwys7LddFPnxLJihROLWS90m1zyEPYeBsYGHgn2qRqkIgIGDy4nHrMW05veYn+R9ENJb5W0W8er4ZGZleH882sP3eLaitka6c01lzfnn6cWyjwqsvU/1UnlgAPgt78tJxazFtdjcvHoyNbvTZwIl15aWeaaitk66dUj8CS9E9iZNHAlABFxatdbmLWI6trKKafA175WTixm/UiPyUXS+cAw0oX9C0kDWd7a4LjMGmvkSHjsscoy11bM6qY3F/TfHBHHAM9ExCnA3sCYxoZl1iARqbZSTCxXXeXEYlZnvWkWezH/XCZpW+ApYLvGhWTWIL4Z0qxpelNzuUrSZsAZwO3APMCP1LPW8cILnRPL/fc7sZg1UG96i309T14p6Spgg4h4trFhmdWJaytmpegyuUh6bzfLiIhfNCYkszqYNw+2q2q9ffZZ2MRPizBrhu5qLod1sywAJxfrm1xbMStdl8klIj7czEDM1tmNN8KBB1aWrVzZ+THEZtZwvonS+ofq2sqGG8KyZeXEYma9eljY+cBRwCcBAUcC4xocl1nvnHVW7YEmnVjMSuWbKK11SXDCCavn3/MeX1sx6yN6k1yqb6Jcjm+itCabOhXa2tLlkys2/lDt2sov3MfErK/ozTWX6psoA/hxQ6MyK5g6FSZNSi1dgeCFwsKzzoLPfKa02MysNsUaNCNIWp9+ehNle3t7zJw5s+wwrIa2NvjT/DGMYVFl+bhg3rxSQjKzTNKsiGivLu+yWUzSmyS9qjB/DHA58HVJWzQmTLMqq1Yxb74qEss+/AkRLFhQYlxm1q3urrlcALwMIGlf4FvApcCzwOTGh2YDntTpmfUiuIn0bPuxY8sIysx6o7vkMjgins7TRwGTI+LKiPgqML7xodmA9fzznS7Yv3aDBYjVTbjDhsHppzc7MDPrrW6Ti6SOC/4HAL8rLOvVzZdma0zqPP5XBCdfOIZx49LiceNg8mSYMKGcEM2sZ90ll8uAP0iaTuqO/CcASeNJTWNrTdJmkq6QdJ+k2ZL2lrSFpBskzck/N8/rStI5kuZKukvSboX9TMzrz5y1Ut0AAA73SURBVJE0sVC+u6S78zbnSLUGm7I+5cEHO3cvXrbslftWJkxIY1GuWpV+OrGY9W1dJpeIOB04AbgE2CdWdysbRLpbf118H7g2InYEdgVmAycCN0bE9sCNeR7gUGD7/JoEnAeQOxWcDOwJ7AGc3JGQ8jqTCtsdso7xWiNJML6qpTUiDeFiZi2p25soI+LmiPhlRLxQKHsgIm5f2wNK2gTYF7go7+/liFgCHA5MyatNAY7I04cDl0ZyM7CZpJHAwcANEfF0RDwD3AAckpdtEhF/zQnx0sK+rC+5/vrOtZVVq3yXvVk/UMZwsa8GFgP/I+kOSRdK2gjYJiIeBcg/t87rjwIWFrZflMu6K19Uo7wTSZMkzZQ0c/Hixev+zqz3JDj44NXzr3/96ufbm1nLKyO5DAF2A86LiDeS7rc+sZv1a33axFqUdy6MmBwR7RHRPmLEiO6jtvr47ndrD91y113lxGNmDVFGclkELIqIW/L8FaRk83hu0iL/fKKwfnGgzNHAIz2Uj65RbmWT4POfXz3/yU+6Ccysn2p6comIx4CFknbIRQcAfwdmAB09viYC0/P0DOCY3GtsL+DZ3Gx2HXCQpM3zhfyDgOvysucl7ZV7iR1T2JeV4b3vrV1bOeeccuIxs4Yr6xF9nwSmSroL+BfgG6QRAN4uaQ7w9jwPcDXwD2AuacDMjwPkGzy/DtyWX6cWbvr8GHBh3uZB4JomvCerRYJf/nL1/JQpda2tFEdLbmtL82ZWvjUauLI/88CVdTZ8OCxdWllW57+14mjJHYYN8w2WZs20xgNXmq2VlStTbaWYWG65pSHXVk46qfMDJ5ctS+VmVi4nF6uf3XeHIVUjA0XAHnvU9TAdTWHz59de7tGSzcrnMcJs3b3wAmy8cWXZo4/Cq15Ve/11UKsprJpHSzYrn5OLrZvqXmBjx3ZdpaiDWk1hRR4t2axvcLOYrZ2HH+6cWJYvb2hige6bvDxaslnf4ZqLrbnqpPJv/wZXXNGUQ3dVMRo3Dj/y2KwPcc3Feu/222sPNNmkxAKpyWvYsMoyN4WZ9T1OLtY7UuoN1uHUU0sZaHLChNT05QeHmfVtbhaz7t1wAxx0UGVZyTfeTpjgZGLW17nmYl2TKhPLjBmlJxYzaw1OLtbZ5Mm1B5o87LBy4jGzluNmMatUnVTuvBN23bWcWMysZbnmYsnnPle7tuLEYmZrwTWXgW7lys7jgT38MGy7bTnxmFm/4JrLQHbQQZWJZautUm3FicXM1pFrLgPR0qXpeSvVZRttVE48ZtbvuOYy0GyxRWViOfjgVFtxYjGzOnLNZaB45BEYNaqybMUKGDy4nHjMrF9zzWUgkCoTy+c+l2orTixm1iCuufRnd94Jb3xjZZnvsDezJnDNpb+SKhPLj3/sxGJmTeOaS39z1VWdh2lxUjGzJnNy6U+q77C/4QY48MByYjGzAc3NYv3BNdfUHrrFicXMSuKaSyuLgEFV3w8WLoTRo8uJx8wsc82lVV14YWViOfDAlGycWMysD3DNpdXUGmhyyRLYdNNy4jEzq8E1l1byta9VJpaPfSzVVpxYzKyPcc2lFSxb1nnsr5degvXWKyceM7MeuObS102YUJlYzjgj1VacWMysD3PNpa968kkYMaKybNWqzl2Ozcz6INdc+qLddqtMLNOmpdqKE4uZtQjXXPqSBx+E8eMryzx0i5m1INdc+or1169MLH/4gxOLmbUs11zKduutsOeelWVOKmbW4pxcylR9DeXee2GnncqJxcysjkprFpM0WNIdkq7K89tJukXSHEk/l7ReLl8/z8/Ny9sK+/hSLr9f0sGF8kNy2VxJJzb7vfXo17+uTCzjx6faihOLmfUTZV5z+TQwuzD/beDsiNgeeAY4NpcfCzwTEeOBs/N6SNoJOBrYGTgE+FFOWIOBc4FDgZ2A9+d1y9fR4+vd715d9sgjMGdOeTGZmTVAKclF0mjgncCFeV7A/sAVeZUpwBF5+vA8T15+QF7/cGBaRLwUEQ8Bc4E98mtuRPwjIl4GpuV1y/WjH1UONHnYYSnZjBxZXkxmZg1S1jWX7wFfAIbn+S2BJRGxIs8vAkbl6VHAQoCIWCHp2bz+KODmwj6L2yysKq+6Yp5ImgRMAhg7duw6vJ1urFgBQ4dWlj33HAwfXnt9M7N+oOk1F0nvAp6IiFnF4hqrRg/L1rS8c2HE5Ihoj4j2EdV3w9fDF75QmVg+85lUW3FiMbN+roxmsbcA75Y0j9RktT+pJrOZpI6a1GjgkTy9CBgDkJdvCjxdLK/apqvy5nn5ZdhmmzQOWLHsrLOYOhXa2lILWVsbTJ3a1MjMzJqi6cklIr4UEaMjoo10Qf53ETEB+D3wvrzaRGB6np6R58nLfxcRkcuPzr3JtgO2B24FbgO2z73P1svHmNGEt5b8/Ofphsgnnkjz3/9+qq0MHcrUqTBpEsyfn4rmz0/zTjBm1t/0pftcvghMk3QacAdwUS6/CPiJpLmkGsvRABFxr6TLgb8DK4BPRMRKAEnHAdcBg4GLI+Lehke/dGl6rsqqVWn+sMNg+vSKLscnnZRGzy9atiyVT5jQ8AjNzJpG4bvBAWhvb4+ZM2eu3cbnngvHHbd6/u9/h9e9rtNqgwbVvvleWp2TzMxaiaRZEdFeXe6xxdbVRRetTiyTJqXsUSOxAHTVIa1RHdXMzMri5LKudtkF3vxmWLAALrig21VPPx2GDassGzYslZuZ9SdOLutqzz3hpptgzJgeV50wASZPhnHjUlPYuHFp3tdbzKy/6UsX9AeECROcTMys/3PNxczM6s7JxczM6s7JxczM6s7JxczM6s7JxczM6s7JxczM6s7JxczM6s5ji2WSFgPzy45jDWwFPFl2ECXzOfA5AJ+Dst//uIjo9EAsJ5cWJWlmrcHiBhKfA58D8Dnoq+/fzWJmZlZ3Ti5mZlZ3Ti6ta3LZAfQBPgc+B+Bz0Cffv6+5mJlZ3bnmYmZmdefkYmZmdefk0mIkjZH0e0mzJd0r6dNlx1QGSYMl3SHpqrJjKYOkzSRdIem+/Lewd9kxNZukz+T/gXskXSZpg7JjajRJF0t6QtI9hbItJN0gaU7+uXmZMXZwcmk9K4ATIuJ1wF7AJyTtVHJMZfg0MLvsIEr0feDaiNgR2JUBdi4kjQI+BbRHxC7AYODocqNqikuAQ6rKTgRujIjtgRvzfOmcXFpMRDwaEbfn6edJHyqjyo2quSSNBt4JXFh2LGWQtAmwL3ARQES8HBFLyo2qFEOADSUNAYYBj5QcT8NFxB+Bp6uKDwem5OkpwBFNDaoLTi4tTFIb8EbglnIjabrvAV8AVpUdSEleDSwG/ic3DV4oaaOyg2qmiHgY+C6wAHgUeDYiri83qtJsExGPQvryCWxdcjyAk0vLkrQxcCVwfEQ8V3Y8zSLpXcATETGr7FhKNATYDTgvIt4IvEAfaQpplnxd4XBgO2BbYCNJHyg3KitycmlBkoaSEsvUiPhF2fE02VuAd0uaB0wD9pf003JDarpFwKKI6KixXkFKNgPJgcBDEbE4IpYDvwDeXHJMZXlc0kiA/POJkuMBnFxajiSR2tpnR8RZZcfTbBHxpYgYHRFtpAu4v4uIAfWNNSIeAxZK2iEXHQD8vcSQyrAA2EvSsPw/cQADrFNDwQxgYp6eCEwvMZZXDCk7AFtjbwE+CNwt6c5c9uWIuLrEmKz5PglMlbQe8A/gwyXH01QRcYukK4DbST0o76CPDoNST5IuA/YDtpK0CDgZ+BZwuaRjSUn3yPIiXM3Dv5iZWd25WczMzOrOycXMzOrOycXMzOrOycXMzOrOycXMzOrOycX6NSV/lnRooezfJV1bckyXS7pL0qeqlp0m6WFJdxZewxscz3WNPoYNPO6KbP2epF2A/yWNwzYYuBM4JCIeXId9DomIFWu57WjgDxHxmhrLTgOejIjvrW1saxCHSJ8BA3WMNmsg11ys34uIe4BfA18k3XR2aUQ8KGmipFtz7eBHkgYBSJosaWZ+VsjXOvYjaZGkr0q6CXhPfp7I3yX9rdYQNJI2lDRF0t2Sbpe0b150PbBtPm6vhiyR9AVJk/P0v+R9bphrOlPyM37mSPpIYZsT8/u7q+N9SBqfn39yPukGxJH5fW2Wl3c6J5KGSFoi6Vv5vf5V0tZ5/VdJmp6P8TdJe3a1nzX6pVnriwi//Or3L2Aj4H7gbmB9YBfgV8CQvHwy8B95eov8cwjwJ2CnPL8I+Gxhn48C6+XpzWoc84vAj/P0zsB8YD1gPHBnF3GeBjxMql3dCfw2lw8CbiIN1ngHsFdh/duBDUij4S4CtgHeAfwIUN72WtLYW+NJo0m/qXDMRcBmXZ2TfB4CODSXnwWcmKevBI4rnK9Nuju3fg2cl4d/sQEhIl6Q9HNgaUS8JOlA4E3AzNQ6xIbAwrz6+/NQGkNII+7uxOqxu35e2O29wE8lTSd9mFbbBzgjH/9eSY+QPtxf7iHcM6KqWSwiVkn6ECnh/DAibi4s/lVE/BP4p6Q/5vd1IHAoKREBbAy8ljSo4YMRcVuN43Z3Tl6MiGvy9CzgrXl6P/JDuiI1Ez7Xw7m1AcLJxQaSVax+BoyAiyPiq8UVJG1PesrlHhGxJDd3FR+f+0Jh+mDgbaTaxFck7RIRK4u7q3P82wNLSQmvqPrCaeRjnxYRFxUXSBpP5XuoWEztczKEyoS4ksrPjurj19yPDSxuB7WB6rfAv0vaCkDSlpLGkpp1nid9Ax9JSiCdSBoMjI6I3wGfB0aQnoZY9EdgQl7/dcBIYO7aBJuviZxNGrh0lKTi0waPkLR+fi9vBWYC1wHHKj9ETNLojvfaja7OSXd+D/xXXn+w0lMy12Y/1s+45mIDUkTcLekU4Lf5YvNy0ofkTFIT2D2k0YZv6mIXQ4Cf5S68g4BvR3rsdNEPgAsk3Z33f0xEvJybirrz+dwE1uEw4HTg+xExV9KHc9x/zstvA64BxgAnR8TjwNWSdgRuzsd7nnT9pEvdnJPuHh98HPBjSf9JGp34PyPi1i72s6CnN279h7sim7WwZnZdNlsTbhYzM7O6c83FzMzqzjUXMzOrOycXMzOrOycXMzOrOycXMzOrOycXMzOru/8PqwtUzS332L8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing the Test set results  \n",
    "mtp.scatter(x_test, y_test, color=\"blue\")   \n",
    "mtp.plot(x_train, x_pred, color=\"red\")    \n",
    "mtp.title(\"Salary vs Experience (Test Dataset)\")  \n",
    "mtp.xlabel(\"Years of Experience\")  \n",
    "mtp.ylabel(\"Salary(In Rupees)\")  \n",
    "mtp.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot, there are observations given by the blue color, and prediction is given by the red regression line. As we can see, most of the observations are close to the regression line, hence we can say our Simple Linear Regression is a good model and able to make good predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above topic, we have learned about Simple Linear Regression, where a single Independent/Predictor(X) variable is used to model the response variable (Y). But there may be various cases in which the response variable is affected by more than one predictor variable; for such cases, the Multiple Linear Regression algorithm is used.\n",
    "\n",
    "Moreover, Multiple Linear Regression is an extension of Simple Linear regression as it takes more than one predictor variable to predict the response variable. We can define it as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression is one of the important regression algorithms which models the linear relationship between a single dependent continuous variable and more than one independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key points about MLR:\n",
    "\n",
    "For MLR, the dependent or target variable(Y) must be the continuous/real, but the predictor or independent variable may be of continuous or categorical form.\n",
    "Each feature variable must model the linear relationship with the dependent variable.\n",
    "MLR tries to fit a regression line through a multidimensional space of data-points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLR equation:\n",
    "In Multiple Linear Regression, the target variable(Y) is a linear combination of multiple predictor variables x1, x2, x3, ...,xn. Since it is an enhancement of Simple Linear Regression, so the same is applied for the multiple linear regression equation, the equation becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y= b<sub>0</sub>+b<sub>1</sub>x<sub>1</sub>+ b<sub>2</sub>x<sub>2</sub>+ b<sub>3</sub>x<sub>3</"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where,\n",
    "\n",
    "Y= Output/Response variable\n",
    "\n",
    "b0, b1, b2, b3 , bn....= Coefficients of the model.\n",
    "\n",
    "x1, x2, x3, x4,...= Various Independent/feature variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where,\n",
    "\n",
    "Y= Output/Response variable\n",
    "\n",
    "b0, b1, b2, b3 , bn....= Coefficients of the model.\n",
    "\n",
    "x1, x2, x3, x4,...= Various Independent/feature variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Multiple Linear Regression model using Python:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4  R&D Spend  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN  165349.20   \n",
       "1         NaN         NaN         NaN         NaN         NaN  162597.70   \n",
       "2         NaN         NaN         NaN         NaN         NaN  153441.51   \n",
       "3         NaN         NaN         NaN         NaN         NaN  144372.41   \n",
       "4         NaN         NaN         NaN         NaN         NaN  142107.34   \n",
       "\n",
       "   Administration  Marketing Spend       State     Profit  \n",
       "0       136897.80        471784.10    New York  192261.83  \n",
       "1       151377.59        443898.53  California  191792.06  \n",
       "2       101145.55        407934.54     Florida  191050.39  \n",
       "3       118671.85        383199.62    New York  182901.99  \n",
       "4        91391.77        366168.42     Florida  166187.94  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    " \n",
    "dataset = pd.read_excel('comPU_list.xlsx')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=[\"Unnamed: 0\",\"Unnamed: 1\",\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"],inplace=True)# dropping the unnamed colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, in the above-shown sample of the dataset, we notice that there are 3 independent variables – R&D spend, Administration and marketing spend.\n",
    "\n",
    "They contribute to the calculation of the dependent variable – Profit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-preprocessing\n",
    "Building the matrix of features and dependent vector.\n",
    "\n",
    "Here, the matrix of features is the matrix of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "         1.3689780e+05, 4.7178410e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "         1.5137759e+05, 4.4389853e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "         1.0114555e+05, 4.0793454e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "         1.1867185e+05, 3.8319962e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n",
       "         9.1391770e+04, 3.6616842e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n",
       "         9.9814710e+04, 3.6286136e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n",
       "         1.4719887e+05, 1.2771682e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n",
       "         1.4553006e+05, 3.2387668e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n",
       "         1.4871895e+05, 3.1161329e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n",
       "         1.0867917e+05, 3.0498162e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0191308e+05,\n",
       "         1.1059411e+05, 2.2916095e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0067196e+05,\n",
       "         9.1790610e+04, 2.4974455e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n",
       "         1.2732038e+05, 2.4983944e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n",
       "         1.3549507e+05, 2.5266493e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n",
       "         1.5654742e+05, 2.5651292e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n",
       "         1.2261684e+05, 2.6177623e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n",
       "         1.2159755e+05, 2.6434606e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n",
       "         1.4507758e+05, 2.8257431e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n",
       "         1.1417579e+05, 2.9491957e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n",
       "         1.5351411e+05, 0.0000000e+00],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n",
       "         1.1386730e+05, 2.9866447e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n",
       "         1.5377343e+05, 2.9973729e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.3994560e+04,\n",
       "         1.2278275e+05, 3.0331926e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n",
       "         1.0575103e+05, 3.0476873e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n",
       "         9.9281340e+04, 1.4057481e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n",
       "         1.3955316e+05, 1.3796262e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n",
       "         1.4413598e+05, 1.3405007e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.2107600e+04,\n",
       "         1.2786455e+05, 3.5318381e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.6051520e+04,\n",
       "         1.8264556e+05, 1.1814820e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n",
       "         1.5303206e+05, 1.0713838e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n",
       "         1.1564128e+05, 9.1131240e+04],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.1136380e+04,\n",
       "         1.5270192e+05, 8.8218230e+04],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n",
       "         1.2921961e+05, 4.6085250e+04],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n",
       "         1.0305749e+05, 2.1463481e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n",
       "         1.5769392e+05, 2.1079767e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n",
       "         8.5047440e+04, 2.0551764e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n",
       "         1.2705621e+05, 2.0112682e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n",
       "         5.1283140e+04, 1.9702942e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.0229590e+04,\n",
       "         6.5947930e+04, 1.8526510e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n",
       "         8.2982090e+04, 1.7499930e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n",
       "         1.1854605e+05, 1.7279567e+05],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.7892920e+04,\n",
       "         8.4710770e+04, 1.6447071e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n",
       "         9.6189630e+04, 1.4800111e+05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n",
       "         1.2738230e+05, 3.5534170e+04],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n",
       "         1.5480614e+05, 2.8334720e+04],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n",
       "         1.2415304e+05, 1.9039300e+03],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n",
       "         1.1581621e+05, 2.9711446e+05],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         1.3542692e+05, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n",
       "         5.1743150e+04, 0.0000000e+00],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         1.1698380e+05, 4.5173060e+04]]),\n",
       " array([192261.83, 191792.06, 191050.39, 182901.99, 166187.94, 156991.12,\n",
       "        156122.51, 155752.6 , 152211.77, 149759.96, 146121.95, 144259.4 ,\n",
       "        141585.52, 134307.35, 132602.65, 129917.04, 126992.93, 125370.37,\n",
       "        124266.9 , 122776.86, 118474.03, 111313.02, 110352.25, 108733.99,\n",
       "        108552.04, 107404.34, 105733.54, 105008.31, 103282.38, 101004.64,\n",
       "         99937.59,  97483.56,  97427.84,  96778.92,  96712.8 ,  96479.51,\n",
       "         90708.19,  89949.14,  81229.06,  81005.76,  78239.91,  77798.83,\n",
       "         71498.49,  69758.98,  65200.33,  64926.08,  49490.75,  42559.73,\n",
       "         35673.41,  14681.4 ]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the categorical variables\n",
    "\n",
    "We have categorical variables in this model. ‘State’ is a categorical variable. We will be using Label Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelEncoder_X = LabelEncoder() \n",
    "X[:,3] = labelEncoder_X.fit_transform(X[ : , 3])\n",
    " \n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "        1.1867185e+05, 3.8319962e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n",
       "        9.1391770e+04, 3.6616842e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n",
       "        9.9814710e+04, 3.6286136e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n",
       "        1.4719887e+05, 1.2771682e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n",
       "        1.4553006e+05, 3.2387668e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n",
       "        1.4871895e+05, 3.1161329e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n",
       "        1.0867917e+05, 3.0498162e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0191308e+05,\n",
       "        1.1059411e+05, 2.2916095e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0067196e+05,\n",
       "        9.1790610e+04, 2.4974455e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n",
       "        1.2732038e+05, 2.4983944e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n",
       "        1.3549507e+05, 2.5266493e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n",
       "        1.5654742e+05, 2.5651292e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n",
       "        1.2261684e+05, 2.6177623e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n",
       "        1.2159755e+05, 2.6434606e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n",
       "        1.4507758e+05, 2.8257431e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n",
       "        1.1417579e+05, 2.9491957e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n",
       "        1.5351411e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n",
       "        1.1386730e+05, 2.9866447e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n",
       "        1.5377343e+05, 2.9973729e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.3994560e+04,\n",
       "        1.2278275e+05, 3.0331926e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n",
       "        1.0575103e+05, 3.0476873e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n",
       "        9.9281340e+04, 1.4057481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n",
       "        1.3955316e+05, 1.3796262e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n",
       "        1.4413598e+05, 1.3405007e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.2107600e+04,\n",
       "        1.2786455e+05, 3.5318381e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.6051520e+04,\n",
       "        1.8264556e+05, 1.1814820e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n",
       "        1.5303206e+05, 1.0713838e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n",
       "        1.1564128e+05, 9.1131240e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.1136380e+04,\n",
       "        1.5270192e+05, 8.8218230e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n",
       "        1.2921961e+05, 4.6085250e+04],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n",
       "        1.0305749e+05, 2.1463481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n",
       "        1.5769392e+05, 2.1079767e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n",
       "        8.5047440e+04, 2.0551764e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n",
       "        1.2705621e+05, 2.0112682e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n",
       "        5.1283140e+04, 1.9702942e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.0229590e+04,\n",
       "        6.5947930e+04, 1.8526510e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n",
       "        8.2982090e+04, 1.7499930e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n",
       "        1.1854605e+05, 1.7279567e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.7892920e+04,\n",
       "        8.4710770e+04, 1.6447071e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n",
       "        9.6189630e+04, 1.4800111e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n",
       "        1.2738230e+05, 3.5534170e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n",
       "        1.5480614e+05, 2.8334720e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n",
       "        1.2415304e+05, 1.9039300e+03],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n",
       "        1.1581621e+05, 2.9711446e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.3542692e+05, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n",
       "        5.1743150e+04, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.1698380e+05, 4.5173060e+04]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have performed Label Encoding first because One hot encoding can be performed only after converting into numerical data. We need numbers to create dummy variables.\n",
    "\n",
    "# Avoiding the dummy variable trap\n",
    "\n",
    "In the below code, we removed the first column from X but put all rows. We ignore only index 0. This is to avoid the dummy variable trap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.6534920e+05, 1.3689780e+05, 4.7178410e+05],\n",
       "       [0.0000000e+00, 1.6259770e+05, 1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 1.5344151e+05, 1.0114555e+05, 4.0793454e+05],\n",
       "       [1.0000000e+00, 1.4437241e+05, 1.1867185e+05, 3.8319962e+05],\n",
       "       [0.0000000e+00, 1.4210734e+05, 9.1391770e+04, 3.6616842e+05],\n",
       "       [1.0000000e+00, 1.3187690e+05, 9.9814710e+04, 3.6286136e+05],\n",
       "       [0.0000000e+00, 1.3461546e+05, 1.4719887e+05, 1.2771682e+05],\n",
       "       [0.0000000e+00, 1.3029813e+05, 1.4553006e+05, 3.2387668e+05],\n",
       "       [1.0000000e+00, 1.2054252e+05, 1.4871895e+05, 3.1161329e+05],\n",
       "       [0.0000000e+00, 1.2333488e+05, 1.0867917e+05, 3.0498162e+05],\n",
       "       [0.0000000e+00, 1.0191308e+05, 1.1059411e+05, 2.2916095e+05],\n",
       "       [0.0000000e+00, 1.0067196e+05, 9.1790610e+04, 2.4974455e+05],\n",
       "       [0.0000000e+00, 9.3863750e+04, 1.2732038e+05, 2.4983944e+05],\n",
       "       [0.0000000e+00, 9.1992390e+04, 1.3549507e+05, 2.5266493e+05],\n",
       "       [0.0000000e+00, 1.1994324e+05, 1.5654742e+05, 2.5651292e+05],\n",
       "       [1.0000000e+00, 1.1452361e+05, 1.2261684e+05, 2.6177623e+05],\n",
       "       [0.0000000e+00, 7.8013110e+04, 1.2159755e+05, 2.6434606e+05],\n",
       "       [1.0000000e+00, 9.4657160e+04, 1.4507758e+05, 2.8257431e+05],\n",
       "       [0.0000000e+00, 9.1749160e+04, 1.1417579e+05, 2.9491957e+05],\n",
       "       [1.0000000e+00, 8.6419700e+04, 1.5351411e+05, 0.0000000e+00],\n",
       "       [0.0000000e+00, 7.6253860e+04, 1.1386730e+05, 2.9866447e+05],\n",
       "       [1.0000000e+00, 7.8389470e+04, 1.5377343e+05, 2.9973729e+05],\n",
       "       [0.0000000e+00, 7.3994560e+04, 1.2278275e+05, 3.0331926e+05],\n",
       "       [0.0000000e+00, 6.7532530e+04, 1.0575103e+05, 3.0476873e+05],\n",
       "       [1.0000000e+00, 7.7044010e+04, 9.9281340e+04, 1.4057481e+05],\n",
       "       [0.0000000e+00, 6.4664710e+04, 1.3955316e+05, 1.3796262e+05],\n",
       "       [0.0000000e+00, 7.5328870e+04, 1.4413598e+05, 1.3405007e+05],\n",
       "       [1.0000000e+00, 7.2107600e+04, 1.2786455e+05, 3.5318381e+05],\n",
       "       [0.0000000e+00, 6.6051520e+04, 1.8264556e+05, 1.1814820e+05],\n",
       "       [1.0000000e+00, 6.5605480e+04, 1.5303206e+05, 1.0713838e+05],\n",
       "       [0.0000000e+00, 6.1994480e+04, 1.1564128e+05, 9.1131240e+04],\n",
       "       [1.0000000e+00, 6.1136380e+04, 1.5270192e+05, 8.8218230e+04],\n",
       "       [0.0000000e+00, 6.3408860e+04, 1.2921961e+05, 4.6085250e+04],\n",
       "       [0.0000000e+00, 5.5493950e+04, 1.0305749e+05, 2.1463481e+05],\n",
       "       [0.0000000e+00, 4.6426070e+04, 1.5769392e+05, 2.1079767e+05],\n",
       "       [1.0000000e+00, 4.6014020e+04, 8.5047440e+04, 2.0551764e+05],\n",
       "       [0.0000000e+00, 2.8663760e+04, 1.2705621e+05, 2.0112682e+05],\n",
       "       [0.0000000e+00, 4.4069950e+04, 5.1283140e+04, 1.9702942e+05],\n",
       "       [1.0000000e+00, 2.0229590e+04, 6.5947930e+04, 1.8526510e+05],\n",
       "       [0.0000000e+00, 3.8558510e+04, 8.2982090e+04, 1.7499930e+05],\n",
       "       [0.0000000e+00, 2.8754330e+04, 1.1854605e+05, 1.7279567e+05],\n",
       "       [0.0000000e+00, 2.7892920e+04, 8.4710770e+04, 1.6447071e+05],\n",
       "       [0.0000000e+00, 2.3640930e+04, 9.6189630e+04, 1.4800111e+05],\n",
       "       [1.0000000e+00, 1.5505730e+04, 1.2738230e+05, 3.5534170e+04],\n",
       "       [0.0000000e+00, 2.2177740e+04, 1.5480614e+05, 2.8334720e+04],\n",
       "       [1.0000000e+00, 1.0002300e+03, 1.2415304e+05, 1.9039300e+03],\n",
       "       [0.0000000e+00, 1.3154600e+03, 1.1581621e+05, 2.9711446e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.3542692e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 5.4205000e+02, 5.1743150e+04, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.1698380e+05, 4.5173060e+04]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the test and train set\n",
    "\n",
    "Generally, we will consider 20% of the dataset to be test set and 80% to be the training set. By training set we mean, we train our model according to these parameters and perform test on the “test set” and check if the output of our testing matches the output given in the dataset earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the test set results\n",
    "We create a vector containing all the predictions of the test set profit. The predicted profits are then put into the vector called y_pred.(contains prediction for all observations in the test set).\n",
    "\n",
    "‘predict’ method makes the predictions for test set. Hence, input is the test set. The parameter for predict must be an array or sparse matrix, hence input is X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n",
       "        81229.06,  97483.56, 110352.25, 166187.94])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103615.70496732, 132245.69745432, 133070.23906339,  72592.46097845,\n",
       "       179075.96157176, 116014.3380813 ,  67853.79186105,  98837.47482921,\n",
       "       114480.26282341, 168492.58649243])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model-fit until now need not be the optimal model for the dataset. When we built the model, we used all the independent variables.\n",
    "\n",
    "But what if among these independent variables there are some statistically significant (having a great impact) dependent variables?\n",
    "\n",
    "What if we also have some variables that are not significant at all?\n",
    "\n",
    "Hence we need an optimal team of independent variables so that each independent variable is powerful and statistically significant and definitely has an effect.\n",
    "\n",
    "This effect can be positive (decrease in 1 unit of the independent variable, profit will increase) or negative (increase in 1 unit of the independent variable, profit will decrease).\n",
    "\n",
    "We will perform backward elimination using stats model. But this topic will not be discussed in this article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "To quickly conclude, the advantages of using linear regression is that it works on any size of the dataset and gives information about the relevance of features. However, these models work on certain assumptions which can be seen as a disadvantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
